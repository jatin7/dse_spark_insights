#/bin/bash

cat << EOF > /etc/dse/collectd/10-spark.conf
LoadPlugin python
<Plugin python>
  ModulePath "/opt/collectd-spark"

  Import spark_plugin

  <Module spark_plugin>
  MetricsURL "http://127.0.0.1"
  MasterPort 7080
  WorkerPorts 7081 7082
  Applications "True"
  Master "http://127.0.0.1:7080"
  Cluster "Standalone"
  </Module>
</Plugin>
EOF

dsetool insights_config --mode ENABLED_WITH_LOCAL_STORAGE

git clone https://github.com/signalfx/collectd-spark

mkdir /usr/share/dse/collectd/collectd-spark
cp collectd-spark/spark_plugin.py /usr/share/dse/collectd/collectd-spark/

git clone https://github.com/datastax/dse-metric-reporter-dashboards.git
cd dse-metric-reporter-dashboards

cat /etc/hosts | grep node | grep -v ext| grep -v allnodes | awk -F' ' '{print $1 ":9103"}'  | jq -R . | jq -s ".| [{targets:[.[]], labels:{cluster: \"test_cluster\" }}]" > prometheus/tg_dse.json

pip install docker-compose

docker-compose up &
